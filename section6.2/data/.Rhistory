Q <- 2         # Sample size for second estimator (second part)
n_sim <- 100000 # Number of Monte Carlo simulations
# First estimator: (1/M sum X_i)^2
first_estimates <- replicate(n_sim, {
sample_X <- rnorm(M, mean = mu, sd = sigma)
mean(sample_X)^2
})
# Second estimator: (1/P sum X_i) * (1/Q sum X_j)
second_estimates <- replicate(n_sim, {
sample_X1 <- rnorm(P, mean = mu, sd = sigma)
sample_X2 <- rnorm(Q, mean = mu, sd = sigma)
mean(sample_X1) * mean(sample_X2)
})
# Compute empirical means of the estimators
first_mean <- mean(first_estimates)
second_mean <- mean(second_estimates)
# True value of (E[X])^2
true_value <- mu^2
# Display results
cat("True (E[X])^2: ", true_value, "\n")
cat("First Estimator Mean: ", first_mean, " (BIAS =", first_mean - true_value, ")\n")
cat("Second Estimator Mean: ", second_mean, " (BIAS =", second_mean - true_value, ")\n")
second_estimates
library(sp)
data("meuse")
meuse
getwd()
write.csv(meuse, "meuse.csv")
write.csv(meuse, "meuse.csv", row.names = F)
write.csv(meuse, "meuse.csv", row.names = F)
write.csv(meuse, "meuse.csv")
meuse
getwd()
library(tidyverse)
write_csv(meuse, "meuse.csv")
write_csv(meuse, "meuse.csv")
write.csv(meuse, "meuse.csv")
library(sp)
library(gstat)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
# Let's inspect the first few rows:
head(meuse)
# 3. Keep only the columns we need:
#    - x, y: the spatial coordinates (in meters, Dutch RD New)
#    - cadmium, copper, lead, zinc: metal concentrations (ppm)
df_meuse <- meuse[, c("x", "y", "cadmium", "copper", "lead", "zinc")]
# 4. Remove any rows with NA values, if any (in meuse, typically there's none, but just in case)
df_meuse <- na.omit(df_meuse)
library(sp)
library(gstat)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
# The 'meuse' data frame has columns:
#   x, y, cadmium, copper, lead, zinc, elev, dist, om, ffreq, soil, lime, landuse, dist.m
# Let's inspect the first few rows:
head(meuse)
# 3. Keep only the columns we need:
#    - x, y: the spatial coordinates (in meters, Dutch RD New)
#    - cadmium, copper, lead, zinc: metal concentrations (ppm)
df_meuse <- meuse[, c("x", "y", "cadmium", "copper", "lead", "zinc")]
# 4. Remove any rows with NA values, if any (in meuse, typically there's none, but just in case)
df_meuse <- na.omit(df_meuse)
# 5. Inspect the structure
str(df_meuse)
# 6. (Optional) Export to CSV if we want to import from Python
#    Suppose we write it to a local CSV in your working directory:
write.csv(df_meuse, file = "meuse_data.csv", row.names = FALSE)
library(sp)
library(gstat)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
# The 'meuse' data frame has columns:
#   x, y, cadmium, copper, lead, zinc, elev, dist, om, ffreq, soil, lime, landuse, dist.m
# Let's inspect the first few rows:
head(meuse)
# 3. Keep only the columns we need:
#    - x, y: the spatial coordinates (in meters, Dutch RD New)
#    - cadmium, copper, lead, zinc: metal concentrations (ppm)
df_meuse <- meuse[, c("x", "y", "cadmium", "copper", "lead", "zinc")]
# 4. Remove any rows with NA values, if any (in meuse, typically there's none, but just in case)
df_meuse <- na.omit(df_meuse)
# 5. Inspect the structure
str(df_meuse)
# 6. (Optional) Export to CSV if we want to import from Python
#    Suppose we write it to a local CSV in your working directory:
write.csv(df_meuse, file = "meuse_data.csv", row.names = FALSE)
setwd("~/research/posterior_attraction/data")
library(sp)
library(gstat)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
# The 'meuse' data frame has columns:
#   x, y, cadmium, copper, lead, zinc, elev, dist, om, ffreq, soil, lime, landuse, dist.m
# Let's inspect the first few rows:
head(meuse)
# 3. Keep only the columns we need:
#    - x, y: the spatial coordinates (in meters, Dutch RD New)
#    - cadmium, copper, lead, zinc: metal concentrations (ppm)
df_meuse <- meuse[, c("x", "y", "cadmium", "copper", "lead", "zinc")]
# 4. Remove any rows with NA values, if any (in meuse, typically there's none, but just in case)
df_meuse <- na.omit(df_meuse)
# 5. Inspect the structure
str(df_meuse)
# 6. (Optional) Export to CSV if we want to import from Python
#    Suppose we write it to a local CSV in your working directory:
write.csv(df_meuse, file = "meuse_data.csv", row.names = FALSE)
meuse %>% View()
meuse
library(tidyverse)
meuse %>% View()
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc, data = df_meuse)
summary(model)
meuse
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc + dist, data = df_meuse)
# 3. Keep only the columns we need:
#    - x, y: the spatial coordinates (in meters, Dutch RD New)
#    - cadmium, copper, lead, zinc: metal concentrations (ppm)
df_meuse <- meuse[, c("x", "y", "cadmium", "copper", "lead", "zinc", "dist")]
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc + dist, data = df_meuse)
summary(model)
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc + dist, data = meuse)
summary(model)
?meuse
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc + elev, data = meuse)
summary(model)
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc + om, data = meuse)
summary(model)
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc, data = meuse)
summary(model)
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ om, data = meuse)
summary(model)
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmiumc, data = meuse)
summary(model)
# Regress lead on cadmium, copper, and zinc
# 7. Fit a linear model
model <- lm(lead ~ cadmium + copper + zinc, data = meuse)
summary(model)
library(sp)
library(gstat)
library(tidyverse)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
# Let's inspect the first few rows:
head(meuse)
# 3. Keep only the columns we need:
#    - x, y: the spatial coordinates (in meters, Dutch RD New)
#    - cadmium, copper, lead, zinc: metal concentrations (ppm)
df_meuse <- meuse[, c("x", "y", "cadmium", "copper", "lead", "zinc", "dist")]
# 4. Remove any rows with NA values, if any (in meuse, typically there's none, but just in case)
df_meuse <- na.omit(df_meuse)
# 5. Inspect the structure
str(df_meuse)
library(sp)
library(gstat)
library(tidyverse)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
# The 'meuse' data frame has columns:
#   x, y, cadmium, copper, lead, zinc, elev, dist, om, ffreq, soil, lime, landuse, dist.m
# Let's inspect the first few rows:
head(meuse)
meuse
?meuse
dim(meuse)
mna = na.omit(meuse)
dim(mna)
meuse
meuse %>% ggplot(aes(x=ffreq, y=zinc)) + geom_boxplot()
meuse %>% ggplot(aes(x=dist, y=zinc)) + geom_point()
meuse %>% ggplot(aes(x=dist, y=zinc)) + geom_point() + geom_smooth()
library(sp)
library(gstat)
library(tidyverse)
Load the Meuse dataset
?meuse
meuse$soil
meuse
?meuse
meuse
data("meuse")
meuse
setwd("C:/Users/roi.naveiro/OneDrive - CUNEF/CUNEF/research/posterior_attraction/data")
# ------------------------------------------------------------------
# 0.  Packages
# ------------------------------------------------------------------
library(sp);   library(dplyr);   library(geoR)
# ------------------------------------------------------------------
# 1.  Load Meuse data and reproduce your preprocessing
# ------------------------------------------------------------------
data(meuse, package = "sp")
meuse <- meuse %>%
mutate(
log_zinc = log(zinc),          # response
dist_sq  = sqrt(dist),         # covariate
ffreq    = factor(ffreq),
soil     = factor(soil),
z_elev   = scale(elev)[, 1],
z_om     = scale(om)[, 1],
# Shift coords to (0,0) and rescale to kilometres
x_km     = (x - min(x))/1000,
y_km     = (y - min(y))/1000
)
meuse <- na.omit(meuse)
# ------------------------------------------------------------------
# 2.  Fit your linear model (no spatial term)
# ------------------------------------------------------------------
ols_fit <- lm(
log_zinc ~ dist_sq + z_elev + z_om,  # soil excluded as you chose
data = meuse
)
# ------------------------------------------------------------------
# 0.  Packages
# ------------------------------------------------------------------
library(sp);   library(dplyr);   library(geoR)
install.packages("geoR")
# ------------------------------------------------------------------
# 0.  Packages
# ------------------------------------------------------------------
library(sp);   library(dplyr);   library(geoR)
install.packages("geoR")
# ------------------------------------------------------------------
# 0.  Packages
# ------------------------------------------------------------------
library(sp);   library(dplyr);   library(geoR)
# ------------------------------------------------------------------
# 1.  Load Meuse data and reproduce your preprocessing
# ------------------------------------------------------------------
data(meuse, package = "sp")
library(geoR)
# ------------------------------------------------------------------
# 0.  Packages
# ------------------------------------------------------------------
library(sp);   library(dplyr);
library(geoR)
# ------------------------------------------------------------------
# 1.  Load Meuse data and reproduce your preprocessing
# ------------------------------------------------------------------
data(meuse, package = "sp")
meuse <- meuse %>%
mutate(
log_zinc = log(zinc),          # response
dist_sq  = sqrt(dist),         # covariate
ffreq    = factor(ffreq),
soil     = factor(soil),
z_elev   = scale(elev)[, 1],
z_om     = scale(om)[, 1],
# Shift coords to (0,0) and rescale to kilometres
x_km     = (x - min(x))/1000,
y_km     = (y - min(y))/1000
)
meuse <- na.omit(meuse)
# ------------------------------------------------------------------
# 2.  Fit your linear model (no spatial term)
# ------------------------------------------------------------------
ols_fit <- lm(
log_zinc ~ dist_sq + z_elev + z_om,  # soil excluded as you chose
data = meuse
)
# ------------------------------------------------------------------
# 3.  Build a geoR 'geodata' object with the RESIDUALS
#     (variogram on residuals removes large‑scale trend)
# ------------------------------------------------------------------
geo  <- as.geodata(
cbind(meuse$x_km, meuse$y_km, resid = residuals(ols_fit)),
coords.col = 1:2,   # x_km, y_km
data.col   = 3      # residuals
)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.5 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 5.  Fit exponential model with nugget using variofit
#     'ini.cov.pars' = (partial sill, phi) initial guesses
# ------------------------------------------------------------------
ini_pars <- c(var(emp_vario$v),  0.5)   # crude start: variance & 0.5 km
vario_mod <- variofit(
emp_vario,
ini.cov.pars = ini_pars,
nugget = 0.1 * var(emp_vario$v),   # 10% of total var as starting nugget
cov.model = "exponential",
weights = "equal"
)
# ------------------------------------------------------------------
# 6.  Extract reasonable hyper‑parameters for PyTorch model
# ------------------------------------------------------------------
sigma2_hat   <- vario_mod$cov.pars[1]   # partial sill  (process variance)
phi_hat_km   <- vario_mod$cov.pars[2]   # decay parameter (km)
nugget_hat   <- vario_mod$nugget        # tau^2
delta2_hat   <- nugget_hat / sigma2_hat # tau^2 / sigma^2
cat("\nSuggested priors for ConjugateSpatialLM:\n",
"  phi    =", round(phi_hat_km, 3), "per km\n",
"  delta2 =", round(delta2_hat, 3), "\n")
nugget_hat
sigma2_hat
nugget_hat
gamma <- function(h){
return(sigma2_hat + nugget_hat) - sigma2_hat*exp(-h/phi_hat_km)
}
0:2:0.1
seq(0,2,0.1)
gamma(h_seq)
h_seq <- seq(0,2,0.1)
h_seq <- seq(0,2,0.1)
gamma_seq <- NULL
for(i in h_seq){
gamma_seq <- c(gamma_seq, gamma(i))
}
plot(h_seq, gamma_seq)
h_seq <- seq(0,2,0.1)
gamma <- function(h){
return(sigma2_hat + nugget_hat) - sigma2_hat*exp(-h/phi_hat_km)
}
h_seq <- seq(0,2,0.1)
gamma_seq <- NULL
for(i in h_seq){
gamma_seq <- c(gamma_seq, gamma(i))
}
gamma_seq
for(i in h_seq){
print(i)
gamma_seq <- c(gamma_seq, gamma(i))
}
a
a
a
a
# ------------------------------------------------------------------
# 6.  Extract reasonable hyper‑parameters for PyTorch model
# ------------------------------------------------------------------
sigma2_hat   <- vario_mod$cov.pars[1]   # partial sill  (process variance)
phi_hat_km   <- vario_mod$cov.pars[2]   # decay parameter (km)
nugget_hat   <- vario_mod$nugget        # tau^2
gamma(0)
gamma(1)
gamma <- function(h){
return(sigma2_hat + nugget_hat) - sigma2_hat*exp(-h/phi_hat_km))
h_seq <- seq(0,2,0.1)
gamma <- function(h){
return(sigma2_hat + nugget_hat - sigma2_hat*exp(-h/phi_hat_km))
}
h_seq <- seq(0,2,0.1)
gamma_seq <- NULL
for(i in h_seq){
print(i)
gamma_seq <- c(gamma_seq, gamma(i))
}
plot(h_seq, gamma_seq)
print(vario_mod)
# ------------------------------------------------------------------
# 5.  Fit exponential model with nugget using variofit
#     'ini.cov.pars' = (partial sill, phi) initial guesses
# ------------------------------------------------------------------
ini_pars <- c(var(emp_vario$v),  0.5)   # crude start: variance & 0.5 km
vario_mod <- variofit(
emp_vario,
ini.cov.pars = ini_pars,
nugget = 0.1 * var(emp_vario$v),   # 10% of total var as starting nugget
cov.model = "exponential",
weights = "equal"
)
print(vario_mod)
# ------------------------------------------------------------------
# 5.  Fit exponential model with nugget using variofit
#     'ini.cov.pars' = (partial sill, phi) initial guesses
# ------------------------------------------------------------------
ini_pars <- c(var(emp_vario$v),  0.5)   # crude start: variance & 0.5 km
vario_mod <- variofit(
emp_vario,
ini.cov.pars = ini_pars,
nugget = 0.1 * var(emp_vario$v),   # 10% of total var as starting nugget
cov.model = "exponential",
weights = "equal"
)
print(vario_mod)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.5 * max(dist(geo$coords)))
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.5 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
par(mfrow=c(1,2))
plot(emp_vario, pch = 19)
plot(h_seq, gamma_seq)
plot(emp_vario, pch = 19)
points(h_seq, gamma_seq)
lines(h_seq, gamma_seq)
par(mfrow=c(1,2))
plot(emp_vario, pch = 19)
lines(h_seq, gamma_seq)
plot(emp_vario, pch = 19)
lines(h_seq, gamma_seq)
plot(emp_vario, pch = 19)
lines(h_seq, gamma_seq)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.25 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.75 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.1 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.01 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.5 * max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 2.0* max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.4* max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 4.  Empirical variogram
#     Choose max.dist as half the maximum interpoint distance
# ------------------------------------------------------------------
emp_vario <- variog(geo, max.dist = 0.5* max(dist(geo$coords)))
plot(emp_vario, pch = 19)        # visual check (optional)
# ------------------------------------------------------------------
# 5.  Fit exponential model with nugget using variofit
#     'ini.cov.pars' = (partial sill, phi) initial guesses
# ------------------------------------------------------------------
ini_pars <- c(var(emp_vario$v),  0.5)   # crude start: variance & 0.5 km
vario_mod <- variofit(
emp_vario,
ini.cov.pars = ini_pars,
nugget = 0.1 * var(emp_vario$v),   # 10% of total var as starting nugget
cov.model = "exponential",
weights = "equal"
)
print(vario_mod)
# ------------------------------------------------------------------
# 6.  Extract reasonable hyper‑parameters for PyTorch model
# ------------------------------------------------------------------
sigma2_hat   <- vario_mod$cov.pars[1]   # partial sill  (process variance)
phi_hat_km   <- vario_mod$cov.pars[2]   # decay parameter (km)
nugget_hat   <- vario_mod$nugget        # tau^2
delta2_hat   <- nugget_hat / sigma2_hat # tau^2 / sigma^2
cat("\nSuggested priors for ConjugateSpatialLM:\n",
"  phi    =", round(phi_hat_km, 3), "per km\n",
"  delta2 =", round(delta2_hat, 3), "\n")
gamma <- function(h){
return(sigma2_hat + nugget_hat - sigma2_hat*exp(-h/phi_hat_km))
}
h_seq <- seq(0,2,0.1)
gamma_seq <- NULL
for(i in h_seq){
print(i)
gamma_seq <- c(gamma_seq, gamma(i))
}
plot(emp_vario, pch = 19)
lines(h_seq, gamma_seq)
library(gstat)
library(tidyverse)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
library(sp)
library(gstat)
library(tidyverse)
# 2. Load the Meuse dataset
data("meuse")  # This loads a data frame called 'meuse' in your global environment.
?meuse
